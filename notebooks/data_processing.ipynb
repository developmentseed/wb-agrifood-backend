{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31800f9c-6f14-45c2-9a92-a94e2bc37950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILE: wb_ag_datasets.csv\n",
      "dict_keys(['name', 'description', 'dataset_id', 'project_id', 'files'])\n",
      "FILE: wb_ag_projects.csv\n",
      "dict_keys(['id', 'project', 'implementer', 'region', 'country', 'documents', 'sectors', 'years', 'contacts'])\n",
      "FILE: wb_youtube_videos.json\n",
      "dict_keys(['link', 'excerpt', 'summary'])\n",
      "FILE: wb_ag_ext_papers.csv\n",
      "dict_keys(['id', 'document', 'abstract', 'date', 'type', 'authors', 'sectors', 'implementer', 'url'])\n",
      "FILE: wb_ag_usecases.csv\n",
      "dict_keys(['id', 'use_case', 'project', 'description', 'implementer', 'region', 'country', 'documents', 'sectors', 'years', 'contacts'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2348"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import tiktoken\n",
    "from openai import OpenAI\n",
    "import concurrent.futures\n",
    "\n",
    "data_files = [\n",
    "    \"wb_ag_datasets.csv\",\t\n",
    "    \"wb_ag_projects.csv\",\t\n",
    "    \"wb_youtube_videos.json\",\n",
    "    \"wb_ag_ext_papers.csv\",\n",
    "    \"wb_ag_usecases.csv\"\n",
    "]\n",
    "data = []\n",
    "\n",
    "for file in data_files: \n",
    "    print(f\"FILE: {file}\")\n",
    "    if file.endswith(\".json\"):\n",
    "        with open(f\"../../data/{file}\") as f: \n",
    "            rows = json.loads(f.read())\n",
    "    else:\n",
    "        with open(f\"../../data/{file}\", \"r\") as f: \n",
    "            rows = [r for r in csv.DictReader(f)]\n",
    "    print(rows[0].keys())\n",
    "    data.extend([\n",
    "        {**row, \"type\": file.replace(\"wb_\", \"\").replace(\"ag_\", \"\").split(\".\")[0][:-1]} for row in rows\n",
    "    ])\n",
    "len(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab57e766-b2dc-4c44-9198-e7bff32c45bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in data: \n",
    "    if not d.get(\"id\") and d.get(\"dataset_id\"): \n",
    "        d[\"id\"] = d[\"dataset_id\"]\n",
    "    elif not d.get(\"id\") and d[\"type\"] == \"youtube_video\": \n",
    "        d[\"video_id\"] = d[\"link\"].replace(\"https://www.youtube.com/watch?v=\", \"\").split(\"&\")[0]\n",
    "        d[\"timestamp\"]= d[\"link\"].replace(\"https://www.youtube.com/watch?v=\", \"\").split(\"&\")[1].replace(\"t=\", \"\")[:-1]\n",
    "        d[\"id\"] = d[\"link\"].replace(\"https://www.youtube.com/watch?v=\", \"\").replace(\"&t=\", \"_\")[:-1]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d5b0073-6d34-42a8-8615-711df3e5dc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in data: \n",
    "    d[\"text_to_embed\"] = \". \".join([v for v in d.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65091cef-36b8-4f8d-a9a7-0fb213374093",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_set = set()\n",
    "for d in data: \n",
    "    key_set.update(set(d.keys()))    \n",
    "data = [{**{k:None for k in key_set}, **d} for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d066f5ce-9fa3-48bb-8c28-b50de5e54baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 2348/2348 [01:14<00:00, 31.65it/s]\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "\n",
    "\n",
    "def get_tokens(text: str):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    return encoding.encode(text)\n",
    "\n",
    "\n",
    "def get_embedding(tokens: list):\n",
    "    \n",
    "    if len(tokens) > 8191:\n",
    "        raise Exception(\"Token length execeeds 8191 tokens, truncating to 8191 tokens\")\n",
    "        tokens = tokens[:8191]\n",
    "\n",
    "    return (\n",
    "        client.embeddings.create(input=tokens, model=\"text-embedding-3-small\")\n",
    "        .data[0]\n",
    "        .embedding\n",
    "    )\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    embeddings = list(\n",
    "        tqdm(\n",
    "            executor.map(\n",
    "                lambda d: get_embedding(get_tokens(d[\"text_to_embed\"])), # some boto3 operation\n",
    "                data\n",
    "            ), \n",
    "            total=len(data) # sets total length of progressbar\n",
    "        )\n",
    "    ) \n",
    "# for d in tqdm(data): \n",
    "#     d[\"embedding\"] = get_embedding(get_tokens(d[\"text_to_embed\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e22fad32-61c6-46c8-bc89-01929d901d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [{**d, \"embedding\": embedding} for d, embedding in zip(data, embeddings)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66e5e1f3-1cb9-45a3-b8bc-137da303569d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"records_v1.0.json\", \"w\") as f: \n",
    "    f.write(json.dumps(data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
